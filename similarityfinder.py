# -*- coding: utf-8 -*-
"""SimilarityFinder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VZ7uSNOt-q8eUTMT0OxBbav_w2UtCtHY
"""

!pip install -Uqq fastai
!pip install nbdev

from fastai.vision.all import *

path = untar_data(URLs.PETS)
files = get_image_files(path/"images")

"""## Siamese"""

def label_func(fname):
    return re.match(r'^(.+)_\d+.jpg$', fname.name).groups()[0]

labels = L(map(label_func, files)).unique()
len(labels)

class SiameseImage(fastuple):
  def show(self, ctx=None, **kwargs):
    if len(self) > 2:
        img1,img2,similarity = self
    else:
        img1,img2 = self
        similarity = 'Undetermined'
    if not isinstance(img1, Tensor):
        if img2.size != img1.size: img2 = img2.resize(img1.size)
        t1,t2 = tensor(img1),tensor(img2)
        t1,t2 = t1.permute(2,0,1),t2.permute(2,0,1)
    else: t1,t2 = img1,img2
    line = t1.new_zeros(t1.shape[0],t1.shape[1],10)
    return show_image(torch.cat([t1,line,t2], dim=2),title=similarity, ctx=ctx, **kwargs)

class SiameseTransform(Transform):
  def __init__(self, files, splits):
    self.splbl2files = [{l:[f for f in files[splits[i]] if label_func(f)==l] for l in labels}
                        for i in range(2)]
    self.valid = {f:self._draw(f,1) for f in files[splits[1]]}
  
  def encodes(self, f):
    f2,same = self.valid.get(f, self._draw(f))
    im1,im2 = PILImage.create(f),PILImage.create(f2)
    return SiameseImage(im1,im2,int(same))

  def _draw(self, f, splits=0):
    same = random.random() <.5
    cls = label_func(f)
    if not same: cls = random.choice([l for l in labels if l != cls])
    return random.choice([f for f in self.splbl2files[splits][cls]]),same

splits = RandomSplitter(seed=23)(files)
tfm = SiameseTransform(files, splits)
tls = TfmdLists(files, tfm, splits=splits)
sdls = tls.dataloaders(after_item=[Resize(224), ToTensor], 
    after_batch=[IntToFloatTensor, Normalize.from_stats(*imagenet_stats)])

show_at(tls,23);

valids = [v[0] for k,v in tfm.valid.items()]
assert not [v for v in valids if v in (files[splits[0]])]

class SiameseModel(Module):
    def __init__(self, encoder, head):
        self.encoder,self.head = encoder,head
    
    def forward(self, x1, x2):
        ftrs = torch.cat([self.encoder(x1), self.encoder(x2)], dim=1)
        return self.head(ftrs)

encoder = create_body(resnet34, cut=-2)

head = create_head(512*2, 2, ps=0.5)

smodel = SiameseModel(encoder, head)

def loss_func(out, targ):
    return CrossEntropyLossFlat()(out, targ.long())

def siamese_splitter(model):
    return [params(model.encoder), params(model.head)]

slearn = Learner(sdls, smodel, loss_func=loss_func, 
                splitter=siamese_splitter, metrics=accuracy)

slearn.freeze()

slearn.fit_one_cycle(4, 3e-3)

slearn.unfreeze()
slearn.fit_one_cycle(3, slice(1e-6,1e-4))

@typedispatch
def show_results(x:SiameseImage, y, samples, outs, ctxs=None, max_n=6, nrows=None, ncols=2, figsize=None, **kwargs):
    if figsize is None: figsize = (ncols*6, max_n//ncols * 3)
    if ctxs is None: ctxs = get_grid(min(x[0].shape[0], max_n), nrows=None, ncols=ncols, figsize=figsize)
    for i,ctx in enumerate(ctxs):
        title = f'Actual: {["Not similar","Similar"][x[2][i].item()]} \n Prediction: {["Not similar","Similar"][torch.argmax(y[2][i]).item()]}'
        SiameseImage(x[0][i], x[1][i], title).show(ctx=ctx)

slearn.show_results()

slearn.save('siamese_learn.pkl')

"""## Classifier"""

cdls = DataBlock(blocks = (ImageBlock, CategoryBlock),
                 get_items = get_image_files,
                 get_y = using_attr(RegexLabeller(r'(.+)_\d+.jpg$'), 'name'),
                 splitter = RandomSplitter(),
                 item_tfms = Resize(224),
                 batch_tfms = aug_transforms()).dataloaders(path/'images')

clearn = cnn_learner(cdls, resnet34, metrics = accuracy, loss_func = LabelSmoothingCrossEntropy()).to_fp16()

clearn.fit_one_cycle(4,3e-3)

clearn.unfreeze()
clearn.fit_one_cycle(5,lr_max=slice(1e-6,1e-4))

clearn.recorder.plot_loss()

clearn.to_fp32()

clearn.save('classifier_learn.pkl')

clearn.show_results()

"""## Inference"""

@patch
def siampredict(self:Learner, item, rm_type_tfms=None, with_input=False):
    return self.predict(item, rm_type_tfms=None, with_input=False)

def label_func(fname):
    return re.match(r'^(.+)_\d+.jpg$', fname.name).groups()[0]

def show_cam(t, cam_map, ctx):
  show_image(t, ctx=ctx)
  ctx.imshow(cam_map[0].detach().cpu(), extent=[0,t.shape[2],t.shape[1],0], 
                 alpha=.6, interpolation='BILINEAR', cmap='magma')

def to_tensor(fn, dls):
  t = first(cdls.test_dl([fn]))[0]
  return dls.decode((t,))[0][0]

def predict_class(fn,learn):
  im = first(learn.dls.test_dl([fn,]))[0].cpu()
  with torch.no_grad(): output = learn.model.eval().cpu()(im)
  return learn.dls.vocab[output.argmax()]

class Hook():
  def __init__(self, m):
    self.hook = m.register_forward_hook(self.hook_func)
    self.stored = []
  def hook_func(self,m,i,o): self.stored.append(o.detach().cpu())
  def reset(self): self.stored = []
  def __enter__(self,*args,**kwargs): return self
  def __exit__(self,*args,**kwargs):  self.hook.remove()

class SimilarityFinder:
  def __init__(self, classifier_learner, siamese_learner, files):
    self.clearn,self.slearn = classifier_learner,siamese_learner
    labels = L(map(label_func, files)).unique()
    self.lbl2files = {l:[f for f in files if label_func(f)==l] 
                      for l in labels}

  def predict(self, fn, compare_n=15):
    self.preds,self.acts,self.images,self.fns = [],[],[],[]
    cls = predict_class(fn,self.clearn)
    compare_fns = self.lbl2files[cls][:compare_n]
    hook_layer = self.slearn.model.encoder
    with Hook(hook_layer) as hook:
      for f2 in compare_fns:
          im1,im2 = PILImage.create(fn),PILImage.create(f2)
          ims = SiameseImage(im1,im2)        
          output = slearn.siampredict(ims)[0][1]
          self.preds.append(torch.sigmoid(output))
          self.fns.append((fn,f2))
          self.images.append((im1,im2))
          self.acts.append(hook.stored)
          hook.reset()
    self.idx = np.array(self.preds).argmax()
    sim_ims = self.images[self.idx]
    title = f'{self.preds[self.idx].item()*100:.2f}% Similarity'
    SiameseImage(sim_ims[0], sim_ims[1], title).show()
    return self.fns[self.idx][1]
    
  def similar_cams(self):
    sweight = self.slearn.model.head[-1].weight.cpu()
    act1,act2 = self.acts[self.idx]
    cam_map1 = torch.einsum('ik,kjl->ijl', sweight, act1[0])
    cam_map2 = torch.einsum('ik,kjl->ijl', sweight, act2[0])
    f1,f2 = self.fns[self.idx]
    t1,t2 = to_tensor(f1,slearn.dls),to_tensor(f2,slearn.dls)
    _,axs = plt.subplots(ncols=2)
    show_cam(t1,cam_map1,axs[0])
    show_cam(t2,cam_map2,axs[1])

simfinder = SimilarityFinder(clearn,slearn,files[:-10])

simfinder.predict(files[-10], 20);

simfinder.similar_cams()